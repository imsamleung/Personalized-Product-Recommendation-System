{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn import over_sampling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    print(\"sensitivity (true positive): {}\".format(cal_sensitivity(cm)))\n",
    "    print(\"specificity (true negative): {}\".format(cal_specificity(cm)))\n",
    "\n",
    "def cal_sensitivity(cm):\n",
    "    FN = cm[1, 0]\n",
    "    TP = cm[1, 1]\n",
    "    return round(TP/float(FN + TP), 2)\n",
    "\n",
    "def cal_specificity(cm):\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    return round(TN / float(TN + FP), 2)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, labels):\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"Confusion Matrix:\\n\")\n",
    "    plot_confusion_matrix(y_true, y_pred, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_json('../../../data/processed/reviews.json.gz', orient=\"records\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting Dataset into Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_reviews[['cleaned_review']]\n",
    "y = df_reviews[['sentiment']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handle Imbalance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of +/- review sentiment before oversampling: \\n{}\".format(y_train.value_counts(normalize=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = over_sampling.RandomOverSampler(random_state=42)\n",
    "\n",
    "x_train_resampled, y_train_resampled = ros.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of +/- review sentiment after oversampling: \\n{}\".format(y_train_resampled.value_counts(normalize=True)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Extraction + Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final = x_train_resampled['cleaned_review'].values\n",
    "x_test_final = x_test['cleaned_review'].values\n",
    "y_train_final = y_train_resampled['sentiment'].values\n",
    "y_test_final = y_test['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipelines_and_search_spaces(vectorizers, estimators):\n",
    "    pipelines = []\n",
    "    search_spaces = []\n",
    "\n",
    "    for v_key in vectorizers:\n",
    "        for e_key in estimators:\n",
    "            # add to pipelines\n",
    "            pipelines.append(Pipeline([\n",
    "                ('vect', vectorizers[v_key]['model']), \n",
    "                ('clf', estimators[e_key]['model'])\n",
    "            ]))\n",
    "            \n",
    "            #add to param grids\n",
    "            search_space = []\n",
    "            for v_item in vectorizers[v_key]['search_spaces']:\n",
    "                for e_item in estimators[e_key]['search_spaces']:\n",
    "                    search_space.append(v_item | e_item)\n",
    "            \n",
    "            search_spaces.append(search_space)\n",
    "    \n",
    "    return pipelines, search_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(pipelines, search_spaces, x_train, y_train, x_test, y_test):\n",
    "    for i, pipeline in enumerate(pipelines):\n",
    "        vect_name = pipeline.named_steps['vect'].__class__.__name__\n",
    "        clf_name = pipeline.named_steps['clf'].__class__.__name__\n",
    "        name = f'{clf_name} with {vect_name}'\n",
    "        \n",
    "        # Train each model using grid search and 5-fold cross-validation\n",
    "        print(f'Training {name}...')\n",
    "        print(pipeline)\n",
    "        print(search_spaces[i])\n",
    "        bayes_search = BayesSearchCV(estimator=pipeline, search_spaces=search_spaces[i], cv=5, n_iter=20, n_jobs=-1, verbose=3)\n",
    "        bayes_search.fit(x_train, y_train)\n",
    "        print(f'{name} trained.\\n')\n",
    "        \n",
    "        # Evaluate the model on the testing set\n",
    "        print(f\"Best hyperparameters for {name}: {bayes_search.best_params_}\")\n",
    "        print(f\"Best estimator: {bayes_search.best_estimator_}\")\n",
    "        print(f\"Best score: {bayes_search.best_score_}\")\n",
    "        y_pred = bayes_search.predict(x_test)\n",
    "        print('Saving the best model...')\n",
    "        pickle.dump(bayes_search.best_estimator_, open(f'../../../models/sentiment_analysis/{clf_name}_with_{vect_name}.pkl', 'wb'))\n",
    "        evaluate_model(y_test, y_pred, labels=[0, 1])\n",
    "        print('---\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    'TfidfVectorizer': \n",
    "    {\n",
    "        'model': TfidfVectorizer(ngram_range=(1, 1)), \n",
    "        'search_spaces': \n",
    "        [\n",
    "            {\n",
    "                'vect__max_features': Integer(low=1000, high=5000),\n",
    "                'vect__stop_words': Categorical(['english']),\n",
    "                'vect__sublinear_tf': Categorical([True])\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    # 'CountVectorizer': \n",
    "    # {\n",
    "    #     'model': CountVectorizer(ngram_range=(1, 1)), \n",
    "    #     'search_spaces': [\n",
    "    #         {\n",
    "    #             'vect__max_features': Integer(low=1000, high=5000),\n",
    "    #             'vect__stop_words': Categorical(['english'])\n",
    "    #         }            \n",
    "    #     ]\n",
    "    # } \n",
    "}\n",
    "\n",
    "estimators = {\n",
    "    'LogisticRegression': \n",
    "    {\n",
    "        'model': LogisticRegression(), \n",
    "        'search_spaces': \n",
    "        [\n",
    "            # {\n",
    "            #     'clf__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "            #     'clf__penalty': Categorical(['l2', None]),\n",
    "            #     'clf__solver': Categorical(['lbfgs', 'newton-cg', 'newton-cholesky', 'sag']),\n",
    "            #     'clf__max_iter': Integer(low=100, high=1000),\n",
    "            # },\n",
    "            {\n",
    "                'clf__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "                'clf__penalty': Categorical(['l1', 'l2']),\n",
    "                'clf__solver': Categorical(['liblinear']),\n",
    "                #'clf__max_iter': Integer(low=100, high=1000),\n",
    "            },\n",
    "            # {\n",
    "            #     'clf__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "            #     'clf__penalty': Categorical(['elasticnet', 'l1', 'l2', None]),\n",
    "            #     'clf__solver': Categorical(['saga']),\n",
    "            #     'clf__max_iter': Integer(low=100, high=1000),\n",
    "            # }\n",
    "        ]\n",
    "    },\n",
    "    # 'RandomForestClassifier': \n",
    "    # {\n",
    "    #     'model': RandomForestClassifier(), \n",
    "    #     'search_spaces': \n",
    "    #     [\n",
    "    #         {\n",
    "    #             'clf__n_estimators': Integer(50, 500),\n",
    "    #             'clf__max_depth': Integer(5, 50),\n",
    "    #             'clf__max_features': Integer(5, 50),\n",
    "    #             'clf__min_samples_split': Integer(2, 20),\n",
    "    #             'clf__min_samples_leaf': Integer(1, 10)\n",
    "    #         }            \n",
    "    #     ]\n",
    "    # },\n",
    "    # 'MultinomialNB': \n",
    "    # {\n",
    "    #     'model': MultinomialNB(), \n",
    "    #     'search_spaces': \n",
    "    #     [\n",
    "    #         {\n",
    "    #             'clf__alpha': Real(low=1e-6, high=1e+6, prior='log-uniform'),\n",
    "    #             'clf__fit_prior': Categorical([True, False])\n",
    "    #         }            \n",
    "    #     ]\n",
    "\n",
    "    # },\n",
    "    # 'DecisionTreeClassifier': \n",
    "    # {\n",
    "    #     'model': DecisionTreeClassifier(), \n",
    "    #     'search_spaces': \n",
    "    #     [\n",
    "    #         {\n",
    "    #             'clf__criterion': Categorical(['gini', 'entropy']),\n",
    "    #             'clf__max_depth': Integer(5, 50),\n",
    "    #             'clf__min_samples_split': Integer(2, 20),\n",
    "    #             'clf__min_samples_leaf': Integer(1, 10)\n",
    "    #         }\n",
    "    #     ]\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines, search_spaces = create_pipelines_and_search_spaces(vectorizers, estimators)\n",
    "print(pipelines)\n",
    "print(search_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models(pipelines, search_spaces, x_train_final, y_train_final, x_test_final, y_test_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
